{"Id":230,"Title":"NGINX引入线程池 性能提升9倍","Slug":"2015-06-24-1","Text":"原文：[nginx.com](http://nginx.com/blog/thread-pools-boost-performance-9x/?comefrom=http://blogread.cn/news/)\n\n\u003cdiv id='ztoc'\u003e\u003c/div\u003e\n\n## 1. 引言(Introduction)\n\nIt’s well known that NGINX uses an [asynchronous, event-driven approach to handling connections](http://nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/). This means that instead of creating another dedicated process or thread for each request (like servers with a traditional architecture), it handles multiple connections and requests in one worker process. To achieve this, NGINX works with sockets in a non-blocking mode and uses efficient methods such as [epoll](http://man7.org/linux/man-pages/man7/epoll.7.html) and [kqueue](https://www.freebsd.org/cgi/man.cgi?query=kqueue).\n\nBecause the number of full-weight processes is small (usually only one per CPU core) and constant, much less memory is consumed and CPU cycles aren’t wasted on task switching. The advantages of such an approach are well-known through the example of NGINX itself. It successfully handles millions of simultaneous requests and scales very well.\n\n正如我们所知，NGINX采用了[异步、事件驱动]((http://nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/)的方法来处理连接。这种处理方式无需（像使用传统架构的服务器一样）为每个请求创建额外的专用进程或者线程，而是在一个工作进程中处理多个连接和请求。为此，NGINX工作在非阻塞的socket模式下，并使用了[epoll](http://man7.org/linux/man-pages/man7/epoll.7.html) 和 [kqueue](https://www.freebsd.org/cgi/man.cgi?query=kqueue)这样有效的方法。\n\n因为满负载进程的数量很少（通常每核CPU只有一个）而且恒定，所以任务切换只消耗很少的内存，而且不会浪费CPU周期。通过NGINX本身的实例，这种方法的优点已经为众人所知。NGINX可以非常好地处理百万级规模的并发请求。\n\n![1](/static/upload/201506241103278.png)\n\n\u003e Each process consumes additional memory, and each switch between them consumes CPU cycles and trashes L-caches\n\n\u003e 每个进程都消耗额外的内存，而且每次进程间的切换都会消耗CPU周期并丢弃CPU高速缓存中的数据。\n\nEach process consumes additional memory, and each switch between them consumes CPU cycles and trashes L-caches\nBut the asynchronous, event-driven approach still has a problem. Or, as I like to think of it, an “enemy”. And the name of the enemy is: **blocking**. Unfortunately, many third-party modules use blocking calls, and users (and sometimes even the developers of the modules) aren’t aware of the drawbacks. Blocking operations can ruin NGINX performance and must be avoided at all costs.\n\nEven in the current official NGINX code it’s not possible to avoid blocking operations in every case, and to solve this problem the new “thread pools” mechanism was [implemented in NGINX version 1.7.11](http://hg.nginx.org/nginx/rev/466bd63b63d1?_ga=1.207653586.1309920492.1435049170). What it is and how it supposed to be used, we will cover later. Now let’s meet face to face with our enemy.\n\n但是，异步、事件驱动方法仍然存在问题。或者，我喜欢将这一问题称为“敌兵”，这个敌兵的名字叫**阻塞（blocking）**。不幸的是，很多第三方模块使用了阻塞调用，然而用户（有时甚至是模块的开发者）并不知道阻塞的缺点。阻塞操作可以毁掉NGINX的性能，我们必须不惜一切代价避免使用阻塞。\n\n即使在当前官方的NGINX代码中，依然无法在全部场景中避免使用阻塞，[NGINX1.7.11](http://hg.nginx.org/nginx/rev/466bd63b63d1?_ga=1.207653586.1309920492.1435049170)中实现的线程池机制解决了这个问题。我们将在后面讲述这个线程池是什么以及该如何使用。现在，让我们先和我们的“敌兵”进行一次面对面的碰撞。\n\n## 2. 问题(The Problem)\n\nFirst, for better understanding of the problem a few words about how NGINX works.\n\nIn general, NGINX is an event handler, a controller that receives information from the kernel about all events occurring on connections and then gives commands to the operating system about what to do. In fact, NGINX does all the hard work by orchestrating the operating system, while the operating system does the routine work of reading and sending bytes. So it’s very important for NGINX to respond fast and in a timely manner.\n\n首先，为了更好地理解这一问题，我们用几句话说明下NGINX是如何工作的。\n\n通常情况下，NGINX是一个事件处理器，即一个接收来自内核的所有连接事件的信息，然后向操作系统发出做什么指令的控制器。实际上，NGINX干了编排操作系统的全部脏活累活，而操作系统做的是读取和发送字节这样的日常工作。所以，对于NGINX来说，快速和及时的响应是非常重要的。\n\n![2](/static/upload/201506241103312.png)\n\n\u003e The worker process listens for and processes events from the kernel\n\n\u003e 工作进程监听并处理来自内核的事件\n\nThe events can be timeouts, notifications about sockets ready to read or to write, or notifications about an error that occurred. NGINX receives a bunch of events and then processes them one by one, doing the necessary actions. Thus all the processing is done in a simple loop over a queue in one thread. NGINX dequeues an event from the queue and then reacts to it by, for example, writing or reading a socket. In most cases, this is extremely quick (perhaps just requiring a few CPU cycles to copy some data into memory) and NGINX proceeds through all of the events in the queue in an instant.\n\n事件可以是超时、socket读写就绪的通知，或者发生错误的通知。NGINX接收大量的事件，然后一个接一个地处理它们，并执行必要的操作。因此，所有的处理过程是通过一个线程中的队列，在一个简单循环中完成的。NGINX从队列中取出一个事件并对其做出响应，比如读写socket。在多数情况下，这种方式是非常快的（也许只需要几个CPU周期，将一些数据复制到内存中），NGINX可以在一瞬间处理掉队列中的所有事件。\n\n![3](/static/upload/2015062411033910.png)\n\n\u003e All processing is done in a simple loop by one thread\n\n\u003e 所有处理过程是在一个简单的循环中，由一个线程完成\n\nBut what will happen if some long and heavy operation has occurred? The whole cycle of event processing will get stuck waiting for this operation to finish.\n\nSo, by saying “a blocking operation” we mean any operation that stops the cycle of handling events for a significant amount of time. Operations can be blocking for various reasons. For example, NGINX might be busy with lengthy, CPU-intensive processing, or it might have to wait to access a resource (such as a hard drive, or a mutex or library function call that gets responses from a database in a synchronous manner, etc.). The key point is that while processing such operations, the worker process cannot do anything else and cannot handle other events, even if there are more system resources available and some events in the queue could utilize those resources.\n\nImagine a salesperson in a store with a long queue in front of him. The first guy in the queue asks for something that is not in the store but is in the warehouse. The salesperson goes to the warehouse to deliver the goods. Now the entire queue must wait a couple of hours for this delivery and everyone in the queue is unhappy. Can you imagine the reaction of the people? The waiting time of every person in the queue is increased by these hours, but the items they intend to buy might be right there in the shop.\n\n但是，如果NGINX要处理的操作是一些又长又重的操作，又会发生什么呢？整个事件处理循环将会卡住，等待这个操作执行完毕。\n\n因此，所谓“阻塞操作”是指任何导致事件处理循环显著停止一段时间的操作。操作可以由于各种原因成为阻塞操作。例如，NGINX可能因长时间、CPU密集型处理，或者可能等待访问某个资源（比如硬盘，或者一个互斥体，亦或要从处于同步方式的数据库获得相应的库函数调用等）而繁忙。关键是在处理这样的操作期间，工作进程无法做其他事情或者处理其他事件，即使有更多的可用系统资源可以被队列中的一些事件所利用。\n\n我们来打个比方，一个商店的营业员要接待他面前排起的一长队顾客。队伍中的第一位顾客想要的某件商品不在店里而在仓库中。这位营业员跑去仓库把东西拿来。现在整个队伍必须为这样的配货方式等待数个小时，队伍中的每个人都很不爽。你可以想见人们的反应吧？队伍中每个人的等待时间都要增加这些时间，除非他们要买的东西就在店里。\n\n![4](/static/upload/201506241103478.png)\n\n\u003e Everyone in the queue has to wait for the first person’s order\n\n\u003e 队伍中的每个人不得不等待第一个人的购买\n\nNearly the same situation happens with NGINX when it asks to read a file that isn’t cached in memory, but needs to be read from disk. Hard drives are slow (especially the spinning ones), and while the other requests waiting in the queue might not need access to the drive, they are forced to wait anyway. As a result, latencies increase and system resources are not fully utilized.\n\n在NGINX中会发生几乎同样的情况，比如当读取一个文件的时候，如果该文件没有缓存在内存中，就要从磁盘上读取。从磁盘（特别是旋转式的磁盘）读取是很慢的,而当队列中等待的其他请求可能不需要访问磁盘时，它们也得被迫等待。导致的结果是，延迟增加并且系统资源没有得到充分利用。\n\n![5](/static/upload/201506241103478.png)\n\n\u003e Just one blocking operation can delay all following operations for a significant time\n\n\u003e 一个阻塞操作足以显著地延缓所有接下来的操作\n\nSome operating systems provide an asynchronous interface for reading and sending files and NGINX can use this interface (see the [aio](http://nginx.org/en/docs/http/ngx_http_core_module.html?\u0026_ga=1.78662356.1309920492.1435049170#aio) directive). A good example here is FreeBSD. Unfortunately, we can’t say the same about Linux. Although Linux provides a kind of asynchronous interface for reading files, it has a couple of significant drawbacks. One of them is alignment requirements for file access and buffers, but NGINX handles that well. But the second problem is worse. The asynchronous interface requires the O_DIRECT flag to be set on the file descriptor, which means that any access to the file will bypass the cache in memory and increase load on the hard disks. That definitely doesn’t make it optimal for many cases.\n\nTo solve this problem in particular, thread pools were introduced in NGINX 1.7.11. They are not included by default in NGINX Plus yet, but [contact sales](http://nginx.com/contact/) if you’d like to try a build of NGINX Plus R6 that has thread pools enabled.\n\nNow let’s dive into what thread pools are about and how they work.\n\n一些操作系统为读写文件提供了异步接口，NGINX可以使用这样的接口（见[AIO](http://nginx.org/en/docs/http/ngx_http_core_module.html?\u0026_ga=1.78662356.1309920492.1435049170#aio)指令）。FreeBSD就是个很好的例子。不幸的是，我们不能在Linux上得到相同的福利。虽然Linux为读取文件提供了一种异步接口，但是存在明显的缺点。其中之一是要求文件访问和缓冲要对齐，但NGINX很好地处理了这个问题。但是，另一个缺点更糟糕。异步接口要求文件描述符中要设置O_DIRECT标记，就是说任何对文件的访问都将绕过内存中的缓存，这增加了磁盘的负载。在很多场景中，这都绝对不是最佳选择。\n\n为了有针对性地解决这一问题，在NGINX 1.7.11中引入了线程池。默认情况下，NGINX+还没有包含线程池，但是如果你想试试的话，可以[联系销售人员](http://nginx.com/contact/)，NGINX+ R6是一个已经启用了线程池的构建版本。\n\n现在，让我们走进线程池，看看它是什么以及如何工作的。\n\n## 3. 线程池(Thread Pools)\n\nLet’s return to our poor sales assistant who delivers goods from a faraway warehouse. But he has become smarter (or maybe he became smarter after being beaten by the crowd of angry clients?) and hired a delivery service. Now when somebody asks for something from the faraway warehouse, instead of going to the warehouse himself, he just drops an order to a delivery service and they will handle the order while our sales assistant will continue serving other customers. Thus only those clients whose goods aren’t in the store are waiting for delivery, while others can be served immediately.\n\n让我们回到那个可怜的，要从大老远的仓库去配货的售货员那儿。这回，他已经变聪明了（或者也许是在一群愤怒的顾客教训了一番之后，他才变得聪明的？），雇用了一个配货服务团队。现在，当任何人要买的东西在大老远的仓库时，他不再亲自去仓库了，只需要将订单丢给配货服务，他们将处理订单，同时，我们的售货员依然可以继续为其他顾客服务。因此，只有那些要买仓库里东西的顾客需要等待配货，其他顾客可以得到即时服务。\n\n![6](/static/upload/201506241103567.png)\n\n\u003e Passing an order to the delivery service unblocks the queue\n\n\u003e 传递订单给配货服务不会阻塞队伍\n\nIn terms of NGINX, the thread pool is performing the functions of the delivery service. It consists of a task queue and a number of threads that handle the queue. When a worker process needs to do a potentially long operation, instead of processing the operation by itself it puts a task in the pool’s queue, from which it can be taken and processed by any free thread.\n\n对NGINX而言，线程池执行的就是配货服务的功能。它由一个任务队列和一组处理这个队列的线程组成。\n当工作进程需要执行一个潜在的长操作时，工作进程不再自己执行这个操作，而是将任务放到线程池队列中，任何空闲的线程都可以从队列中获取并执行这个任务。\n\n![7](/static/upload/201506241104001.png)\n\n\u003e The worker process offloads blocking operations to the thread pool\n\n\u003e 工作进程将阻塞操作卸给线程池\n\nIt seems then we have another queue. Right. But in this case the queue is limited by a specific resource. We can’t read from a drive faster than the drive is capable of producing data. Now at least the drive doesn’t delay processing of other events and only the requests that need to access files are waiting.\n\nThe “reading from disk” operation is often used as the most common example of a blocking operation, but actually the thread pools implementation in NGINX can be used for any tasks that aren’t appropriate to process in the main working cycle.\n\nAt the moment, offloading to thread pools is implemented only for two essential operations: the read() syscall on most operating systems and sendfile() on Linux. We will continue to test and benchmark the implementation, and we may offload other operations to the thread pools in future releases if there’s a clear benefit.\n\n那么，这就像我们有了另外一个队列。是这样的，但是在这个场景中，队列受限于特殊的资源。磁盘的读取速度不能比磁盘产生数据的速度快。不管怎么说，至少现在磁盘不再延误其他事件，只有访问文件的请求需要等待。\n\n“从磁盘读取”这个操作通常是阻塞操作最常见的示例，但是实际上，NGINX中实现的线程池可用于处理任何不适合在主循环中执行的任务。\n\n目前，卸载到线程池中执行的两个基本操作是大多数操作系统中的read()系统调用和Linux中的sendfile()。接下来，我们将对线程池进行测试（test）和基准测试（benchmark），在未来的版本中，如果有明显的优势，我们可能会卸载其他操作到线程池中。\n\n## 4. 基准测试(Benchmarking)\n\nt’s time to move from theory to practice. To demonstrate the effect of using thread pools we are going to perform a synthetic benchmark that simulates the worst mix of blocking and non-blocking operations.\n\nIt requires a data set that is guaranteed not to fit in memory. On a machine with 48 GB of RAM, we have generated 256 GB of random data in 4-MB files, and then have configured NGINX 1.9.0 to serve it.\n\nThe configuration is pretty simple:\n\n现在让我们从理论过度到实践。我们将进行一次模拟基准测试（synthetic benchmark），模拟在阻塞操作和非阻塞操作的最差混合条件下，使用线程池的效果。\n\n另外，我们需要一个内存肯定放不下的数据集。在一台48GB内存的机器上，我们已经产生了每文件大小为4MB的随机数据，总共256GB，然后配置NGINX，版本为1.9.0。\n\n配置很简单：\n\n    worker_processes 16;\n\n    events {\n        accept_mutex off;\n    }\n\n    http {\n        include mime.types;\n        default_type application/octet-stream;\n\n        access_log off;\n        sendfile on;\n        sendfile_max_chunk 512k;\n\n        server {\n            listen 8000;\n\n            location / {\n                root /storage;\n            }\n        }\n    }\n\nAs you can see, to achieve better performance some tuning was done: [logging](http://nginx.org/en/docs/http/ngx_http_log_module.html?\u0026_ga=1.249113159.1309920492.1435049170#access_log) and [accept_mutex](http://nginx.org/en/docs/ngx_core_module.html?\u0026_ga=1.53165288.1309920492.1435049170#accept_mutex) were disabled, [sendfile](http://nginx.org/en/docs/http/ngx_http_core_module.html?\u0026_ga=1.53165288.1309920492.1435049170#sendfile) was enabled, and [sendfile_max_chunk](http://nginx.org/en/docs/http/ngx_http_core_module.html?\u0026_ga=1.253830728.1309920492.1435049170#sendfile_max_chunk) was set. The last directive can reduce the maximum time spent in blocking sendfile() calls, since NGINX won’t try to send the whole file at once, but will do it in 512-KB chunks.\n\nThe machine has two Intel Xeon E5645 (12 cores, 24 HT-threads in total) processors and a 10-Gbps network interface. The disk subsystem is represented by four Western Digital WD1003FBYX hard drives arranged in a RAID10 array. All of this hardware is powered by Ubuntu Server 14.04.1 LTS.\n\n如上所示，为了达到更好的性能，我们调整了几个参数：禁用了[logging](http://nginx.org/en/docs/http/ngx_http_log_module.html?\u0026_ga=1.249113159.1309920492.1435049170#access_log)和 [accept_mutex](http://nginx.org/en/docs/ngx_core_module.html?\u0026_ga=1.53165288.1309920492.1435049170#accept_mutex) ，同时，启用了[sendfile](http://nginx.org/en/docs/http/ngx_http_core_module.html?\u0026_ga=1.53165288.1309920492.1435049170#sendfile) 并设置了[sendfile_max_chunk](http://nginx.org/en/docs/http/ngx_http_core_module.html?\u0026_ga=1.253830728.1309920492.1435049170#sendfile_max_chunk)的大小。最后一个指令可以减少阻塞调用sendfile()所花费的最长时间，因为NGINX不会尝试一次将整个文件发送出去，而是每次发送大小为512KB的块数据。\n\n这台测试服务器有2个Intel Xeon E5645处理器（共计：12核、24超线程）和10-Gbps的网络接口。磁盘子系统是由4块西部数据WD1003FBYX 磁盘组成的RAID10阵列。所有这些硬件由Ubuntu服务器14.04.1 LTS供电。\n\n![8](/static/upload/201506241104056.png)\n\n\u003e Configuration of load generators and NGINX for the benchmark \n\n\u003e 为基准测试配置负载生成器和NGINX\n\nThe clients are represented by two machines with the same specifications. On one of these machines, wrk creates load using a Lua script. The script requests files from our server in a random order using 200 parallel connections, and each request is likely to result in a cache miss and a blocking read from disk. Let’s call this load the random load.\n\nOn the second client machine we will run another copy of **wrk** that will request the same file multiple times using 50 parallel connections. Since this file will be frequently accessed, it will remain in memory all the time. In normal circumstances, NGINX would serve these requests very quickly, but performance will fall if the worker processes are blocked by other requests. Let’s call this load the constant load.\n\nThe performance will be measured by monitoring throughput of the server machine using **ifstat** and by obtaining **wrk** results from the second client.\n\nNow, the first run without thread pools does not give us very exciting results:\n\n客户端有2台服务器，它们的规格相同。在其中一台上，在**wrk**中使用Lua脚本创建了负载程序。脚本使用200个并行连接向服务器请求文件，每个请求都可能未命中缓存而从磁盘阻塞读取。我们将这种负载称作随机负载。\n\n在另一台客户端机器上，我们将运行wrk的另一个副本，使用50个并行连接多次请求同一个文件。因为这个文件将被频繁地访问，所以它会一直驻留在内存中。在正常情况下，NGINX能够非常快速地服务这些请求，但是如果工作进程被其他请求阻塞的话，性能将会下降。我们将这种负载称作恒定负载。\n\n性能将由服务器上**ifstat**监测的吞吐率（throughput）和从第二台客户端获取的**wrk**结果来度量。\n\n现在，没有使用线程池的第一次运行将不会带给我们非常振奋的结果：\n\n    % ifstat -bi eth2\n    eth2\n    Kbps in  Kbps out\n    5531.24  1.03e+06\n    4855.23  812922.7\n    5994.66  1.07e+06\n    5476.27  981529.3\n    6353.62  1.12e+06\n    5166.17  892770.3\n    5522.81  978540.8\n    6208.10  985466.7\n    6370.79  1.12e+06\n    6123.33  1.07e+06\n\nAs you can see, with this configuration the server is able to produce about 1 Gbps of traffic in total. In the output from top, we can see that all of worker processes spend most of the time in blocking I/O (they are in a D state):\n\n如上所示，使用这种配置，服务器产生的总流量约为1Gbps。从下面所示的top输出，我们可以看到，工作进程的大部分时间花在阻塞I/O上（它们处于top的D状态）：\n\n    top - 10:40:47 up 11 days,  1:32,  1 user,  load average: 49.61, 45.77 62.89\n    Tasks: 375 total,  2 running, 373 sleeping,  0 stopped,  0 zombie\n    %Cpu(s):  0.0 us,  0.3 sy,  0.0 ni, 67.7 id, 31.9 wa,  0.0 hi,  0.0 si,  0.0 st\n    KiB Mem:  49453440 total, 49149308 used,   304132 free,    98780 buffers\n    KiB Swap: 10474236 total,    20124 used, 10454112 free, 46903412 cached Mem\n\n      PID USER     PR  NI    VIRT    RES     SHR S  %CPU %MEM    TIME+ COMMAND\n     4639 vbart    20   0   47180  28152     496 D   0.7  0.1  0:00.17 nginx\n     4632 vbart    20   0   47180  28196     536 D   0.3  0.1  0:00.11 nginx\n     4633 vbart    20   0   47180  28324     540 D   0.3  0.1  0:00.11 nginx\n     4635 vbart    20   0   47180  28136     480 D   0.3  0.1  0:00.12 nginx\n     4636 vbart    20   0   47180  28208     536 D   0.3  0.1  0:00.14 nginx\n     4637 vbart    20   0   47180  28208     536 D   0.3  0.1  0:00.10 nginx\n     4638 vbart    20   0   47180  28204     536 D   0.3  0.1  0:00.12 nginx\n     4640 vbart    20   0   47180  28324     540 D   0.3  0.1  0:00.13 nginx\n     4641 vbart    20   0   47180  28324     540 D   0.3  0.1  0:00.13 nginx\n     4642 vbart    20   0   47180  28208     536 D   0.3  0.1  0:00.11 nginx\n     4643 vbart    20   0   47180  28276     536 D   0.3  0.1  0:00.29 nginx\n     4644 vbart    20   0   47180  28204     536 D   0.3  0.1  0:00.11 nginx\n     4645 vbart    20   0   47180  28204     536 D   0.3  0.1  0:00.17 nginx\n     4646 vbart    20   0   47180  28204     536 D   0.3  0.1  0:00.12 nginx\n     4647 vbart    20   0   47180  28208     532 D   0.3  0.1  0:00.17 nginx\n     4631 vbart    20   0   47180    756     252 S   0.0  0.1  0:00.00 nginx\n     4634 vbart    20   0   47180  28208     536 D   0.0  0.1  0:00.11 nginx\n     4648 vbart    20   0   25232   1956    1160 R   0.0  0.0  0:00.08 top\n    25921 vbart    20   0  121956   2232    1056 S   0.0  0.0  0:01.97 sshd\n    25923 vbart    20   0   40304   4160    2208 S   0.0  0.0  0:00.53 zsh\n\nIn this case the throughput is limited by the disk subsystem, while the CPU is idle most of the time. The results from wrk are also very low:\n\n在这种情况下，吞吐率受限于磁盘子系统，而CPU在大部分时间里是空闲的。从wrk获得的结果也非常低：\n\n    Running 1m test @ http://192.0.2.1:8000/1/1/1\n      12 threads and 50 connections\n      Thread Stats   Avg    Stdev     Max  +/- Stdev\n        Latency     7.42s  5.31s   24.41s   74.73%\n        Req/Sec     0.15    0.36     1.00    84.62%\n      488 requests in 1.01m, 2.01GB read\n    Requests/sec:      8.08\n    Transfer/sec:     34.07MB\n\nAnd remember, this is for the file that should be served from memory! The excessively large latencies are because all the worker processes are busy with reading files from the drives to serve the random load created by 200 connections from the first client, and cannot handle our requests in good time.\n\nIt’s time to put our thread pools in play. For this we just add the [aio](http://nginx.org/en/docs/http/ngx_http_core_module.html?\u0026_ga=1.39463779.1309920492.1435049170#aio) **threads** directive to the **location** block:\n\n请记住，文件是从内存送达的！第一个客户端的200个连接创建的随机负载，使服务器端的全部的工作进程忙于从磁盘读取文件，因此产生了过大的延迟，并且无法在合理的时间内处理我们的请求。\n\n现在，我们的线程池要登场了。为此，我们只需在location块中添加[aio](http://nginx.org/en/docs/http/ngx_http_core_module.html?\u0026_ga=1.39463779.1309920492.1435049170#aio)  **threads**指令：\n\n    location / {\n        root /storage;\n        aio threads;\n    }\n\nand ask NGINX to reload its configuration.\n\nAfter that we repeat the test:\n\n接着，执行NGINX reload重新加载配置。\n\n然后，我们重复上述的测试：\n\n    % ifstat -bi eth2\n    eth2\n    Kbps in  Kbps out\n    60915.19  9.51e+06\n    59978.89  9.51e+06\n    60122.38  9.51e+06\n    61179.06  9.51e+06\n    61798.40  9.51e+06\n    57072.97  9.50e+06\n    56072.61  9.51e+06\n    61279.63  9.51e+06\n    61243.54  9.51e+06\n    59632.50  9.50e+06\n\nNow our server produces **9.5 Gbps**, compared to ~1 Gbps without thread pools!\n\nIt probably could produce even more, but it has already reached the practical maximum network capacity, so in this test NGINX is limited by the network interface. The worker processes spend most of the time just sleeping and waiting for new events (they are in **S** state in **top**):\n\n现在，我们的服务器产生的流量是**9.5Gbps**，相比之下，没有使用线程池时只有约1Gbps！\n\n理论上还可以产生更多的流量，但是这已经达到了机器的最大网络吞吐能力，所以在这次NGINX的测试中，NGINX受限于网络接口。工作进程的大部分时间只是休眠和等待新的事件（它们处于**top**的**S**状态）：\n\n    top - 10:43:17 up 11 days,  1:35,  1 user,  load average: 172.71, 93.84, 77.90\n    Tasks: 376 total,  1 running, 375 sleeping,  0 stopped,  0 zombie\n    %Cpu(s):  0.2 us,  1.2 sy,  0.0 ni, 34.8 id, 61.5 wa,  0.0 hi,  2.3 si,  0.0 st\n    KiB Mem:  49453440 total, 49096836 used,   356604 free,    97236 buffers\n    KiB Swap: 10474236 total,    22860 used, 10451376 free, 46836580 cached Mem\n\n      PID USER     PR  NI    VIRT    RES     SHR S  %CPU %MEM    TIME+ COMMAND\n     4654 vbart    20   0  309708  28844     596 S   9.0  0.1  0:08.65 nginx\n     4660 vbart    20   0  309748  28920     596 S   6.6  0.1  0:14.82 nginx\n     4658 vbart    20   0  309452  28424     520 S   4.3  0.1  0:01.40 nginx\n     4663 vbart    20   0  309452  28476     572 S   4.3  0.1  0:01.32 nginx\n     4667 vbart    20   0  309584  28712     588 S   3.7  0.1  0:05.19 nginx\n     4656 vbart    20   0  309452  28476     572 S   3.3  0.1  0:01.84 nginx\n     4664 vbart    20   0  309452  28428     524 S   3.3  0.1  0:01.29 nginx\n     4652 vbart    20   0  309452  28476     572 S   3.0  0.1  0:01.46 nginx\n     4662 vbart    20   0  309552  28700     596 S   2.7  0.1  0:05.92 nginx\n     4661 vbart    20   0  309464  28636     596 S   2.3  0.1  0:01.59 nginx\n     4653 vbart    20   0  309452  28476     572 S   1.7  0.1  0:01.70 nginx\n     4666 vbart    20   0  309452  28428     524 S   1.3  0.1  0:01.63 nginx\n     4657 vbart    20   0  309584  28696     592 S   1.0  0.1  0:00.64 nginx\n     4655 vbart    20   0  30958   28476     572 S   0.7  0.1  0:02.81 nginx\n     4659 vbart    20   0  309452  28468     564 S   0.3  0.1  0:01.20 nginx\n     4665 vbart    20   0  309452  28476     572 S   0.3  0.1  0:00.71 nginx\n     5180 vbart    20   0   25232   1952    1156 R   0.0  0.0  0:00.45 top\n     4651 vbart    20   0   20032    752     252 S   0.0  0.0  0:00.00 nginx\n    25921 vbart    20   0  121956   2176    1000 S   0.0  0.0  0:01.98 sshd\n    25923 vbart    20   0   40304   3840    2208 S   0.0  0.0  0:00.54 zsh\n\nThere are still plenty of CPU resources.\n\nThe results of **wrk**:\n\n如上所示，基准测试中还有大量的CPU资源剩余。\n\n**wrk**的结果如下：\n\n    Running 1m test @ http://192.0.2.1:8000/1/1/1\n      12 threads and 50 connections\n      Thread Stats   Avg      Stdev     Max  +/- Stdev\n        Latency   226.32ms  392.76ms   1.72s   93.48%\n        Req/Sec    20.02     10.84    59.00    65.91%\n      15045 requests in 1.00m, 58.86GB read\n    Requests/sec:    250.57\n    Transfer/sec:      0.98GB\n\nThe average time to serve a 4-MB file has been reduced from 7.42 seconds to 226.32 milliseconds (33 times less), and the number of requests per second has increased by 31 times (250 vs 8)!\n\nThe explanation is that our requests no longer wait in the events queue for processing while worker processes are blocked on reading, but are handled by free threads. As long as the disk subsystem is doing its job as best it can serving our random load from the first client machine, NGINX uses the rest of the CPU resources and network capacity to serve requests of the second client from memory.\n\n服务器处理4MB文件的平均时间从7.42秒降到226.32毫秒（减少了33倍），每秒请求处理数提升了31倍（250 vs 8）！\n\n对此，我们的解释是请求不再因为工作进程被阻塞在读文件，而滞留在事件队列中，等待处理，它们可以被空闲的进程处理掉。只要磁盘子系统能做到最好，就能服务好第一个客户端上的随机负载，NGINX可以使用剩余的CPU资源和网络容量，从内存中读取，以服务于上述的第二个客户端的请求。\n\n## 5. 依然没有银弹(Still Not a Silver Bullet)\n\nAfter all our fears about blocking operations and some exciting results, probably most of you already are going to configure thread pools on your servers. Don’t hurry.\n\nThe truth is that fortunately most read and send file operations do not deal with slow hard drives. If you have enough RAM to store the data set, then an operating system will be clever enough to cache frequently used files in a so-called “page cache”.\n\nThe page cache works pretty well and allows NGINX to demonstrate great performance in almost all common use cases. Reading from the page cache is quite quick and no one can call such operations “blocking.” On the other hand, offloading to a thread pool has some overhead.\n\nSo if you have a reasonable amount of RAM and your working data set isn’t very big, then NGINX already works in the most optimal way without using thread pools.\n\nOffloading read operations to the thread pool is a technique applicable to very specific tasks. It is most useful where the volume of frequently requested content doesn’t fit into the operating system’s VM cache. This might be the case with, for instance, a heavily loaded NGINX-based streaming media server. This is the situation we’ve simulated in our benchmark.\n\nIt would be great if we could improve the offloading of read operations into thread pools. All we need is an efficient way to know if the needed file data is in memory or not, and only in the latter case should the reading operation be offloaded to a separate thread.\n\nTurning back to our sales analogy, currently the salesman cannot know if the requested item is in the store and must either always pass all orders to the delivery service or always handle them himself.\n\nThe culprit is that operating systems are missing this feature. The first attempts to add it to Linux as the fincore() syscall were in 2010 but that didn’t happen. Later there were a number of attempts to implement it as a new preadv2() syscall with the RWF_NONBLOCK flag (see [Non-blocking buffered file read operations](https://lwn.net/Articles/612483/) and [Asynchronous buffered read operations](https://lwn.net/Articles/636967/) at LWN.net for details). The fate of all these patches is still unclear. The sad point here is that it seems the main reason why these patches haven’t been accepted yet to the kernel is continuous [bikeshedding](http://bikeshed.com/).\n\nOn the other hand, users of FreeBSD don’t need to worry at all. FreeBSD already has a sufficiently good asynchronous interface for reading files, which you should use instead of thread pools.\n\n在抛出我们对阻塞操作的担忧并给出一些令人振奋的结果后，可能大部分人已经打算在你的服务器上配置线程池了。先别着急。\n\n实际上，最幸运的情况是，读取和发送文件操作不去处理缓慢的硬盘驱动器。如果我们有足够多的内存来存储数据集，那么操作系统将会足够聪明地在被称作“页面缓存”的地方，缓存频繁使用的文件。\n\n“页面缓存”的效果很好，可以让NGINX在几乎所有常见的用例中展示优异的性能。从页面缓存中读取比较快，没有人会说这种操作是“阻塞”。而另一方面，卸载任务到一个线程池是有一定开销的。\n\n因此，如果内存有合理的大小并且待处理的数据集不是很大的话，那么无需使用线程池，NGINX已经工作在最优化的方式下。\n\n卸载读操作到线程池是一种适用于非常特殊任务的技术。只有当经常请求的内容的大小，不适合操作系统的虚拟机缓存时，这种技术才是最有用的。至于可能适用的场景，比如，基于NGINX的高负载流媒体服务器。这正是我们已经模拟的基准测试的场景。\n\n我们如果可以改进卸载读操作到线程池，将会非常有意义。我们只需要知道所需的文件数据是否在内存中，只有不在内存中时，读操作才应该卸载到一个单独的线程中。\n\n再回到售货员那个比喻的场景中，这回，售货员不知道要买的商品是否在店里，他必须要么总是将所有的订单提交给配货服务，要么总是亲自处理它们。\n\n人艰不拆，操作系统缺少这样的功能。第一次尝试是在2010年，人们试图将这一功能添加到Linux作为fincore()系统调用，但是没有成功。后来还有一些尝试，是使用RWF_NONBLOCK标记作为preadv2()系统调用来实现这一功能（详情见[LWN.net上的非阻塞缓冲文件读取操作](https://lwn.net/Articles/612483/)和[异步缓冲读操作](https://lwn.net/Articles/636967/)）。但所有这些补丁的命运目前还不明朗。悲催的是，这些补丁尚没有被内核接受的主要原因，貌似是因为旷日持久的撕逼大战（[bikeshedding](http://bikeshed.com/)）。\n\n另一方面，FreeBSD的用户完全不必担心。FreeBSD已经具备足够好的异步读取文件接口，我们应该用这个接口而不是线程池。\n\n## 6. 配置线程池(Configuring Thread Pools)\n\nSo if you are sure that you can get some benefit out of using thread pools in your use case, then it’s time to dive deep into configuration.\n\nThe configuration is quite easy and flexible. The first thing you should have is NGINX version 1.7.11 or later, compiled with the `--with-threads` configuration parameter. In the simplest case, the configuration looks very plain. All you need is to include the [aio](http://nginx.org/en/docs/http/ngx_http_core_module.html?\u0026_ga=1.6503666.1309920492.1435049170#aio) `threads` directive in the `http,` `server`, or `location` context:\n\n所以，如果你确信在你的场景中使用线程池可以带来好处，那么现在是时候深入了解线程池的配置了。\n\n线程池的配置非常简单、灵活。首先，获取NGINX 1.7.11或更高版本的源代码，使用`--with-threads`配置参数编译。在最简单的场景中，配置看起来很朴实。我们只需要在`http`、 `server`，或者location上下文中包含[aio](http://nginx.org/en/docs/http/ngx_http_core_module.html?\u0026_ga=1.6503666.1309920492.1435049170#aio) `threads`指令即可：\n\n    aio threads;\n\nThis is the minimal possible configuration of thread pools. In fact, it’s a short version of the following configuration:\n\n这是线程池的最简配置。实际上的精简版本示例如下：\n\n    thread_pool default threads=32 max_queue=65536;\n    aio threads=default;\n\nIt defines a thread pool called `default` with 32 working threads and a maximum length for the task queue of 65536 requests. If the task queue is overloaded, NGINX logs this error and rejects the request:\n\n这里定义了一个名为`“default”`，包含32个线程，任务队列最多支持65536个请求的线程池。如果任务队列过载，NGINX将输出如下错误日志并拒绝请求：\n\n    thread pool \"NAME\" queue overflow: N tasks waiting\n\nThe error means it’s possible that the threads aren’t able to handle the work as quickly as it is added to the queue. You can try increasing the maximum queue size, but if that doesn’t help, then it indicates that your system is not capable of serving so many requests.\n\nAs you already noticed, with the [thread_pool](http://nginx.org/r/thread_pool?_ga=1.78800724.1309920492.1435049170) directive you can configure the number of threads, the maximum length of the queue, and the name of a specific thread pool. The last implies that you can configure several independent thread pools and use them in different places of your configuration file to serve different purposes:\n\n错误输出意味着线程处理作业的速度有可能低于任务入队的速度了。你可以尝试增加队列的最大值，但是如果这无济于事，那么这说明你的系统没有能力处理如此多的请求了。\n\n正如你已经注意到的，你可以使用 [thread_pool](http://nginx.org/r/thread_pool?_ga=1.78800724.1309920492.1435049170)指令，配置线程的数量、队列的最大值，以及线程池的名称。最后要说明的是，可以配置多个独立的线程池，将它们置于不同的配置文件中，用做不同的目的：\n\n    http {\n        thread_pool one threads=128 max_queue=0;\n        thread_pool two threads=32;\n\n        server {\n            location /one {\n                aio threads=one;\n            }\n\n            location /two {\n                aio threads=two;\n            }\n        }\n    …\n    }\n\nIf the **max_queue** parameter isn’t specified, the value 65536 is used by default. As shown, it’s possible to set **max_queue** to zero. In this case the thread pool will only be able to handle as many tasks as there are threads configured; no tasks will wait in the queue.\n\nNow let’s imagine you have a server with three hard drives and you want this server to work as a «caching proxy» that caches all responses from your back ends. The expected amount of cached data far exceeds the available RAM. It’s actually a caching node for your personal CDN. Of course in this case the most important thing is to achieve maximum performance from the drives.\n\nOne of your options is to configure a RAID array. This approach has its pros and cons. Now with NGINX you can take another one:\n\n如果没有指定**max_queue**参数的值，默认使用的值是65536。如上所示，可以设置**max_queue**为0。在这种情况下，线程池将使用配置中全部数量的线程，尽可能地同时处理多个任务；队列中不会有等待的任务。\n\n现在，假设我们有一台服务器，挂了3块硬盘，我们希望把该服务器用作“缓存代理”，缓存后端服务器的全部响应信息。预期的缓存数据量远大于可用的内存。它实际上是我们个人CDN的一个缓存节点。毫无疑问，在这种情况下，最重要的事情是发挥硬盘的最大性能。\n\n我们的选择之一是配置一个RAID阵列。这种方法毁誉参半，现在，有了NGINX，我们可以有其他的选择：\n\n    # 我们假设每块硬盘挂载在相应的目录中：/mnt/disk1、/mnt/disk2、/mnt/disk3\n\n    proxy_cache_path /mnt/disk1 levels=1:2 keys_zone=cache_1:256m max_size=1024G\n                     use_temp_path=off;\n    proxy_cache_path /mnt/disk2 levels=1:2 keys_zone=cache_2:256m max_size=1024G\n                     use_temp_path=off;\n    proxy_cache_path /mnt/disk3 levels=1:2 keys_zone=cache_3:256m max_size=1024G\n                     use_temp_path=off;\n\n    thread_pool pool_1 threads=16;\n    thread_pool pool_2 threads=16;\n    thread_pool pool_3 threads=16;\n\n    split_clients $request_uri $disk {\n        33.3%     1;\n        33.3%     2;\n        *         3;\n    }\n\n    location / {\n        proxy_pass http://backend;\n        proxy_cache_key $request_uri;\n        proxy_cache cache_$disk;\n        aio threads=pool_$disk;\n        sendfile on;\n    }\n\nn this configuration three independent caches are used, dedicated to each of the disks, and three independent thread pools are dedicated to the disks as well.\n\nThe [split_clients](http://nginx.org/en/docs/http/ngx_http_split_clients_module.html?_ga=1.7479922.1309920492.1435049170) module is used for load balancing between the caches (and as a result between the disks), which perfectly fits this task.\n\nThe **use_temp_path=off** parameter to the [proxy_cache_path](http://nginx.org/en/docs/http/ngx_http_proxy_module.html?\u0026_ga=1.7479922.1309920492.1435049170#proxy_cache_path) directive instructs NGINX to save temporary files into the same directories where the corresponding cache data is located. It is needed to avoid copying response data between the hard drives when updating our caches.\n\nAll this together allows us to get maximum performance out of the current disk subsystem, because NGINX through separate thread pools interacts with the drives in parallel and independently. Each of the drives is served by 16 independent threads with a dedicated task queue for reading and sending files.\n\nI bet your clients like this custom-tailored approach. Be sure that your hard drives like it too.\n\nThis example is a good demonstration of how flexibly NGINX can be tuned specifically for your hardware. It’s like you are giving instructions to NGINX about the best way to interact with the machine and your data set. And by fine-tuning NGINX in user space, you can ensure that your software, operating system, and hardware work together in the most optimal mode to utilize all the system resources as effectively as possible.\n\n在这份配置中，使用了3个独立的缓存，每个缓存专用一块硬盘，另外，3个独立的线程池也各自专用一块硬盘。\n\n缓存之间（其结果就是磁盘之间）的负载均衡使用split_clients模块，split_clients非常适用于这个任务。\n\n在 [split_clients](http://nginx.org/en/docs/http/ngx_http_split_clients_module.html?_ga=1.7479922.1309920492.1435049170)指令中设置**use_temp_path=off**，表示NGINX会将临时文件保存在缓存数据的同一目录中。这是为了避免在更新缓存时，磁盘之间互相复制响应数据。\n\n这些调优将带给我们磁盘子系统的最大性能，因为NGINX通过单独的线程池并行且独立地与每块磁盘交互。每块磁盘由16个独立线程和读取和发送文件专用任务队列提供服务。\n\n我敢打赌，你的客户喜欢这种量身定制的方法。请确保你的磁盘也持有同样的观点。\n\n这个示例很好地证明了NGINX可以为硬件专门调优的灵活性。这就像你给NGINX下了一道命令，让机器和数据用最佳姿势来搞基。而且，通过NGINX在用户空间中细粒度的调优，我们可以确保软件、操作系统和硬件工作在最优模式下，尽可能有效地利用系统资源。\n\n## 7. 总结(Conclusion)\n\nSumming up, thread pools is a great feature that pushes NGINX to new levels of performance by eliminating one of its well-known and long-time enemies – blocking – especially when we are speaking about really large volumes of content.\n\nAnd there is even more to come. As previously mentioned, this brand-new interface potentially allows offloading of any long and blocking operation without any loss of performance. NGINX opens up new horizons in terms of having a mass of new modules and functionality. Lots of popular libraries still do not provide an asynchronous non-blocking interface, which previously made them incompatible with NGINX. We may spend a lot of time and resources on developing our own non-blocking prototype of some library, but will it always be worth the effort? Now, with thread pools on board, it is possible to use such libraries relatively easily, making such modules without an impact on performance.\n\nStay tuned.\n\n综上所述，线程池是一个伟大的功能，将NGINX推向了新的性能水平，除掉了一个众所周知的长期危害——阻塞——尤其是当我们真正面对大量内容的时候。\n\n甚至，还有更多的惊喜。正如前面提到的，这个全新的接口，有可能没有任何性能损失地卸载任何长期阻塞操作。NGINX在拥有大量的新模块和新功能方面，开辟了一方新天地。许多流行的库仍然没有提供异步非阻塞接口，此前，这使得它们无法与NGINX兼容。我们可以花大量的时间和资源，去开发我们自己的无阻塞原型库，但这么做始终都是值得的吗？现在，有了线程池，我们可以相对容易地使用这些库，而不会影响这些模块的性能","Tags":["Nginx"],"CreateTime":1435115136,"EditTime":1437544502,"UpdateTime":1435115136,"IsComment":true,"IsLinked":false,"AuthorId":10,"Template":"blog.html","Type":"article","Status":"publish","Format":"markdown","Comments":[],"Hits":1265}